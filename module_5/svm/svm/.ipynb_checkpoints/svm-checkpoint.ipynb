{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt.solvers\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_SUPPORT_VECTOR_MULTIPLIER = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMTrainer(object):\n",
    "    def __init__(self, kernel, c=0.1):\n",
    "        self._kernel = kernel\n",
    "        self._c = c\n",
    "\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "            X: martix of features\n",
    "            y: vector of labels\n",
    "\n",
    "            next step: Compute lagrange multipliers by calling _compute_lagrange_multipliers method\n",
    "            retrun:    Return Predictor object by calling _create_predictor method\n",
    "        \"\"\"\n",
    "        lagrange_multipliers = self._compute_lagrange_multipliers(X, y)\n",
    "        return self._create_predictor(X, y, lagrange_multipliers)\n",
    "\n",
    "\n",
    "    def _kernel_matrix(self, X):\n",
    "        \"\"\"\n",
    "            X: martix of features\n",
    "\n",
    "            next step: Get number of samples\n",
    "            next step: Create zero matrix of quadratic shape of number of samples \n",
    "            next step: Calculate kernels\n",
    "            retrun:    Return Kernels matrix\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "\n",
    "        print(X)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i,j] = self._kernel(X[i], X[j])\n",
    "        \n",
    "\n",
    "        #for i, x_i in enumerate(X):\n",
    "            #for j, x_j in enumerate(X):\n",
    "                #K[i, j] = self._kernel(x_i, x_j)\n",
    "\n",
    "        return K\n",
    "\n",
    "\n",
    "    def _create_predictor(self, X, y, lagrange_multipliers):\n",
    "        \"\"\"\n",
    "            X: martix of features\n",
    "            y: vector of labels\n",
    "            lagrange_multipliers: vector of langrange multipliers\n",
    "\n",
    "            next step: Get non-zero lagrange multipliers indicies\n",
    "            next step: Get non-zero lagrange multipliers\n",
    "            next step: Get support vecorts\n",
    "            next step: Get support vecort labels\n",
    "            next step: Ð¡ompute bias (use avg trick)\n",
    "            retrun   : Return SVMPredictor object\n",
    "        \"\"\"\n",
    "\n",
    "        support_vector_indices = lagrange_multipliers > MIN_SUPPORT_VECTOR_MULTIPLIER\n",
    "\n",
    "        support_multipliers = lagrange_multipliers[support_vector_indices]\n",
    "\n",
    "        support_vectors = X[support_vector_indices]\n",
    "\n",
    "        support_vector_labels = y[support_vector_indices]\n",
    "\n",
    "        bias = np.mean(\n",
    "            [y_k - SVMPredictor(\n",
    "                    kernel=self._kernel,\n",
    "                    bias=0.0,\n",
    "                    weights=support_multipliers,\n",
    "                    support_vectors=support_vectors,\n",
    "                    support_vector_labels=support_vector_labels\n",
    "                ).predict(x_k) for (y_k, x_k) in zip(support_vector_labels, support_vectors)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return SVMPredictor(\n",
    "            kernel=self._kernel,\n",
    "            bias=0.0,\n",
    "            weights=support_multipliers,\n",
    "            support_vectors=support_vectors,\n",
    "            support_vector_labels=support_vector_labels\n",
    "        )\n",
    "\n",
    "\n",
    "    def _compute_lagrange_multipliers(self, X, y):\n",
    "        \"\"\"\n",
    "            X: martix of features\n",
    "            y: vector of labels\n",
    "\n",
    "\n",
    "            Need to Solve\n",
    "                min 1/2 x^T P x + q^T x (aplha is x)\n",
    "                s.t.\n",
    "                    Gx <= h (alpha >= 0)\n",
    "                    Ax = b (y^T * alpha = 0)\n",
    "\n",
    "\n",
    "            next step: Get number of samples\n",
    "            next step: Create Kernel matrix by calling _kernel_matrix method\n",
    "            next step: Create create quadratic term P based on Kernel matrix\n",
    "            next step: Create linear term q\n",
    "            next step: Create G, h, A, b\n",
    "            next step: Solve with - cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "            retrun:    Return flatten solution['x']\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        K = self._kernel_matrix(X)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "\n",
    "        q = cvxopt.matrix(-1 * np.ones(n_samples))\n",
    "\n",
    "        G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "\n",
    "        h = cvxopt.matrix(np.zeros(n_samples))\n",
    "\n",
    "        A = cvxopt.matrix(y, (1, n_samples))\n",
    "\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "\n",
    "        # Check this\n",
    "\n",
    "        # -a_i \\leq 0\n",
    "        G_std = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "        h_std = cvxopt.matrix(np.zeros(n_samples))\n",
    "\n",
    "        # # a_i \\leq c\n",
    "        G_slack = cvxopt.matrix(np.diag(np.ones(n_samples)))\n",
    "        h_slack = cvxopt.matrix(np.ones(n_samples) * self._c)\n",
    "\n",
    "        G = cvxopt.matrix(np.vstack((G_std, G_slack)))\n",
    "        h = cvxopt.matrix(np.vstack((h_std, h_slack)))\n",
    "\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        return np.ravel(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVMPredictor(object):\n",
    "    def __init__(self,\n",
    "                kernel,\n",
    "                bias,\n",
    "                weights,\n",
    "                support_vectors,\n",
    "                support_vector_labels\n",
    "            ):\n",
    "        \n",
    "        self._kernel = kernel\n",
    "        self._bias = bias\n",
    "        self._weights = weights\n",
    "        self._support_vectors = support_vectors\n",
    "        self._support_vector_labels = support_vector_labels\n",
    "\n",
    "\n",
    "        assert len(support_vectors) == len(support_vector_labels)\n",
    "        assert len(weights) == len(support_vector_labels)\n",
    "\n",
    "\n",
    "        logging.info(\"Bias: %s\", self._bias)\n",
    "        logging.info(\"Weights: %s\", self._weights)\n",
    "        logging.info(\"Support vectors: %s\", self._support_vectors)\n",
    "        logging.info(\"Support vector labels: %s\", self._support_vector_labels)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Computes the SVM prediction on the given features x.\n",
    "        \"\"\"\n",
    "        result = self._bias\n",
    "        for w_i, x_i, y_i in zip(self._weights,\n",
    "                                 self._support_vectors,\n",
    "                                 self._support_vector_labels):\n",
    "            result += w_i * y_i * self._kernel(x_i, x)\n",
    "\n",
    "        return np.sign(result).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
